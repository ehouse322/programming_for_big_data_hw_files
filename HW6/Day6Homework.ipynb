{"nbformat": 4, "nbformat_minor": 0, "metadata": {"anaconda-cloud": {}, "language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "version": "3.5.1", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "mimetype": "text/x-python", "name": "python"}, "kernelspec": {"language": "python", "name": "Python [Root]", "display_name": "Python [Root]"}}, "cells": [{"source": ["# Question 1\n", "\n", "Write a function that takes any url as a string and returns the response from a `GET` request.\n", "\n", "*Hint*: You can use http://httpbin.org/ to test your function.\n", "\n", "    def get_response(url):\n", "        '''\n", "        Performs a GET request for a given url and returns the response.\n", "\n", "        Parameters:\n", "        -----------\n", "        url : (str)\n", "            web address we want to request\n", "\n", "        Returns:\n", "        --------\n", "        response : (requests.response)   \n", "            output of the request\n", "\n", "        Notes:\n", "        ------\n", "        1. If the url is invalid or points to a non-existing address, your code\n", "            should return None.\n", "        '''"], "metadata": {}, "cell_type": "markdown"}, {"source": ["# Question 2\n", "\n", "Write a function that converts Erik Durm's wikipedia page (the one we used in the [lecture](../Special-Topics/Web-Scraping.ipynb#Beautiful-Soup,-so-rich-and-green,-Waiting-in-a-hot-tureen!)) into a soup object and extracts the `<p>` element that starts with \"In the 2013\u201314 Bundesliga season...\". Your function must return the Beautiful Soup's `Tag` object itself.\n", "\n", "    def extract_bundesliga_p_tag(wiki_path):\n", "        '''\n", "        Extracts the <p> tag from ErikDurmWiki that starts with:\n", "        \"In the 2013-14 Bundesliga season.\n", "\n", "        Parameters:\n", "        -----------\n", "        wiki_path : (str)\n", "            Path to Erik Durm's wikipedia page in the Data folder.\n", "\n", "        Returns:\n", "        --------\n", "        p_tag : (bs4.element.tag)   \n", "            Beautiful Soup's tag object containing the paragraph in question.\n", "        '''"], "metadata": {}, "cell_type": "markdown"}, {"source": ["# Question 3\n", "\n", "In the Data folder you will find another previously scraped webpage containing the lyrics to Pink Floyd's Wish You Were Here: [Pink Floyd Lyrics](../Data/pink_floyd_wish.html)\n", "\n", "Write a function that converts this page into a soup and returns a list with the song's title and lyrics. Format the lyrics as a list of strings, with each string being a line in the lyrics. Remove all newline characters, empty lines, and html tags. \n", "Hint: You can use 'inspect element' to look at the source code for the lyrics in the above link\n", "\n", "    def extract_pink_floyd_lyrics(lyrics_path):\n", "        '''\n", "        Extracts the title and lyrics of Pink Floyd's Wish You Were Here song.\n", "\n", "        Parameters:\n", "        -----------\n", "        lyrics_path : (str)\n", "            Path to the lyrics page in the Data folder.\n", "\n", "        Returns:\n", "        --------\n", "        lyrics_info : (list)\n", "            List where the first element is the song's title (string)\n", "            and second element is a list of strings with the lyrics\n", "        '''"], "metadata": {"collapsed": false}, "cell_type": "markdown"}, {"source": ["# Question 4\n", "\n", "In class you wrote a function that converted your Hexaco results page to a soup and extracted the `(name, your score)` pairs for each personality scale. \n", "\n", "Now write a function that extracts the `(name, median score)` pairs for each personality scale.\n", "\n", "    def extract_median_scores(hexaco_path):\n", "        '''\n", "        Extracts the median scores as well as the name of each personality\n", "        scale from the hexaco's results page.\n", "\n", "        Parameters:\n", "        -----------\n", "        hexaco_path : (str)\n", "            Path to the html page with your hexaco scores.\n", "\n", "        Returns:\n", "        --------\n", "        name_medians : (list of pairs)   \n", "            List of pairs (tuple or list), with each pair being: (scale name (str), median score (float))\n", "        '''"], "metadata": {}, "cell_type": "markdown"}, {"execution_count": null, "source": [], "metadata": {"collapsed": true}, "cell_type": "code", "outputs": []}]}